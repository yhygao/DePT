# loop logistics
epochs: 15
start_epoch: 0
eval_interval: 1
print_freq: 10

# loss
epsilon: 0.1
warmup_iters: 0
random_seed: 0

alpha: 1.0
beta: 1.0
beta2: 0.5
lam: 0.1
prompt_div: False

tau: 1.0

teacher_init_temp: 0.07
warmup_epoch: 0
eval_freq: 1
