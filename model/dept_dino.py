from copy import deepcopy
import logging

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import math
from PIL import Image, ImageFilter, ImageOps
import random
import pdb

class GaussianBlur(object):
    """
    Apply Gaussian Blur to the PIL image.
    """
    def __init__(self, p=0.5, radius_min=0.1, radius_max=2.):
        self.prob = p
        self.radius_min = radius_min
        self.radius_max = radius_max

    def __call__(self, img):
        do_it = random.random() <= self.prob
        if not do_it:
            return img

        return img.filter(
            ImageFilter.GaussianBlur(
                radius=random.uniform(self.radius_min, self.radius_max)
            )
        )


class Solarization(object):
    """
    Apply Solarization to the PIL image.
    """
    def __init__(self, p):
        self.p = p

    def __call__(self, img):
        if random.random() < self.p:
            return ImageOps.solarize(img)
        else:
            return img



def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)


class DINOHead(nn.Module):
    def __init__(self, in_dim, out_dim, use_bn=False, norm_last_layer=True, nlayers=3, hidden_dim=2048, bottleneck_dim=256):
        super().__init__()
        
        self.nlayers = nlayers
        assert nlayers >= 0
        if nlayers == 0:
            self.mlp = nn.Identity()
        
        elif nlayers == 1:
            self.mlp = nn.Linear(in_dim, bottleneck_dim)
        else:
            layers = [nn.Linear(in_dim, hidden_dim)]
            if use_bn:
                layers.append(nn.BatchNorm1d(hidden_dim))
            layers.append(nn.GELU())
            for _ in range(nlayers - 2):
                layers.append(nn.Linear(hidden_dim, hidden_dim))
                if use_bn:
                    layers.append(nn.BatchNorm1d(hidden_dim))
                layers.append(nn.GELU())
            layers.append(nn.Linear(hidden_dim, bottleneck_dim))
            self.mlp = nn.Sequential(*layers)

        if nlayers > 0:
            self.apply(self._init_weights)
            self.last_layer = nn.utils.weight_norm(nn.Linear(bottleneck_dim, out_dim, bias=False))
            self.last_layer.weight_g.data.fill_(1)
            if norm_last_layer:
                self.last_layer.weight_g.requires_grad = False
    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
    def forward(self, x):
        x = self.mlp(x)
        x = nn.functional.normalize(x, dim=-1, p=2)
        if self.nlayers > 0:
            x = self.last_layer(x)
        return x


class DataAugmentationDINO(object):
    def __init__(self, global_crops_scale, local_crops_scale, local_crops_number, return_test=False):
        flip_and_color_jitter = transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomApply(
                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)],
                p=0.8
            ),
            transforms.RandomGrayscale(p=0.2),
        ])
        normalize = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ])
        
        self.return_test = return_test
        self.test_transfo = transforms.Compose([
            transforms.Resize([256, 256]),
            transforms.CenterCrop(224),
            normalize,
        ])


        # weak aug
        self.weak_transfo = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop(224),
            transforms.RandomHorizontalFlip(),
            normalize,
        ])
        
        # first global crop
        self.global_transfo1 = transforms.Compose([
            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(1.0),
            normalize,
        ])

        # second global crop
        self.global_transfo2 = transforms.Compose([
            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(0.1),
            Solarization(0.2),
            normalize,
        ])
        
        self.global_transfo = transforms.Compose([
            #transforms.RandomAffine(degrees=(-15, 15)),
            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            #Solarization(0.2),
            GaussianBlur(0.5),
            normalize,
        ])


        # transformation for the local small crops
        self.local_crops_number = local_crops_number
        self.local_transfo = transforms.Compose([
            transforms.RandomResizedCrop(96, scale=local_crops_scale, interpolation=Image.BICUBIC),
                flip_and_color_jitter,
                GaussianBlur(p=0.5),
                normalize,
        ])
    def __call__(self, image):
        crops = []
        crops.append(self.weak_transfo(image))
        crops.append(self.global_transfo(image))
        crops.append(self.global_transfo(image))
        for _ in range(self.local_crops_number):
            crops.append(self.local_transfo(image))

        if self.return_test:
            crops.append(self.test_transfo(image))

        return crops


class DePTDino(nn.Module):
    """
    Build a Dino model with: a student, a teacher and centering
    https://arxiv.org/pdf/2104.14294.pdf
    """

    def __init__(
        self,
        student,
        teacher,
        m=0.99,
        nlayer_head=0,
        dino_out_dim=65536,
        consistency_type='cls',
        hierarchy=False,
        norm_last_layer=True,
        checkpoint_path=None,
    ):
        """
        m: moco momentum of updating key encoder (default: 0.999)
        """
        super().__init__()
        
        self.consistency_type = consistency_type
        self.hierarchy = hierarchy
        # create the encoders
        self.student = student
        self.teacher = teacher
        self.m = m
        self.dino_out_dim = dino_out_dim
        self.norm_last_layer = norm_last_layer
        
        
        # create DINO head 
        feature_dim = student.output_dim
        if not self.hierarchy:
            self.student_dinohead = DINOHead(feature_dim, dino_out_dim, norm_last_layer=norm_last_layer,
                            nlayers=nlayer_head, hidden_dim=2048, bottleneck_dim=256)
            self.teacher_dinohead = DINOHead(feature_dim, dino_out_dim, norm_last_layer=norm_last_layer,
                            nlayers=nlayer_head, hidden_dim=2048, bottleneck_dim=256)
        else:
            self.student_dinohead = nn.ModuleList()
            self.teacher_dinohead = nn.ModuleList()
            for i in range(len(self.student.encoder_list)):
                self.student_dinohead.append(DINOHead(feature_dim, dino_out_dim, norm_last_layer=norm_last_layer,
                                nlayers=nlayer_head, hidden_dim=2048, bottleneck_dim=256))
                self.teacher_dinohead.append(DINOHead(feature_dim, dino_out_dim, norm_last_layer=norm_last_layer,
                                nlayers=nlayer_head, hidden_dim=2048, bottleneck_dim=256))
               
            
        
        # freeze teacher model
        self.teacher.requires_grad_(False)
        self.teacher_dinohead.requires_grad_(False)


        if checkpoint_path:
            self.load_from_checkpoint(checkpoint_path)
    
    def set_m(self, m):
        self.m = m
        print("set momentum", m)

    def get_full_params(self, fix_ss_head=False):
        backbone_params, extra_params = self.student.get_full_params()

        if not fix_ss_head:
            extra_params.extend(self.student_dinohead.parameters())
        else:
            self.student_dinohead.requires_grad_(False)

        return backbone_params, extra_params

    def get_prompt_params(self, fix_ss_head=False):
        backbone_params, extra_params = self.student.get_prompt_params()

        if not fix_ss_head:
            extra_params.extend(self.student_dinohead.parameters())
        else:
            self.student_dinohead.requires_grad_(False)
        return backbone_params, extra_params

    def get_ln_params(self, fix_ss_head=False):
        backbone_params, extra_params = self.student.get_ln_params()

        if not fix_ss_head:
            extra_params.extend(self.student_dinohead.parameters())
        else:
            self.student_dinohead.requires_grad_(False)

        return backbone_params, extra_params


    def load_from_checkpoint(self, checkpoint_path, same_student_teacher=False):
        checkpoint = torch.load(checkpoint_path, map_location="cpu")
        state_dict = dict()
        student_dict = dict()
        student_dinohead_dict = dict()
        for name, param in checkpoint["state_dict"].items():
            # get rid of 'module.' prefix brought by DDP
            name = name[len("module.") :] if name.startswith("module.") else name
            state_dict[name] = param

            if name.startswith("student."):
                student_dict[name[len("student.") :]] = param
            if name.startswith("student_dinohead."):
                student_dinohead_dict[name[len("student_dinohead.") :]] = param

        if not same_student_teacher:
            msg = self.load_state_dict(state_dict, strict=True)
            logging.info(
                f"Loaded from {checkpoint_path}; missing params: {msg.missing_keys}"
            )
        else:
            self.student.load_state_dict(student_dict, strict=True)
            self.teacher.load_state_dict(student_dict, strict=True)
            self.student_dinohead.load_state_dict(student_dinohead_dict, strict=True)
            self.teacher_dinohead.load_state_dict(student_dinohead_dict, strict=True)

            logging.info(f"Loaded from {checkpoint_path}; Student and Teacher use the same weights")

    @torch.no_grad()
    def _momentum_update_teacher(self):
        """
        Momentum update of the key encoder
        """
        # encoder_q -> encoder_k
        for param_q, param_k in zip(
            self.student.parameters(), self.teacher.parameters()
        ):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)
        for param_q, param_k in zip(
            self.student_dinohead.parameters(), self.teacher_dinohead.parameters()
        ):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)

    def multi_crop_forward(self, x, mode='student'):
    
        if mode == 'student':
            dino_head = self.student_dinohead
            model = self.student
        else:
            dino_head = self.teacher_dinohead
            model = self.teacher

        #feat_out, logits_out, prompt_out = model(torch.cat(x), return_feats=True)
        feat_out, logits_out, prompt_out = model(x, return_feats=True)


    
        if self.consistency_type == 'cls':
            # only add DINO consistency on CLS token
            return dino_head(feat_out), logits_out, None

        else:
    
            if not self.hierarchy:
                B, PN, D = prompt_out[-1].shape
                if 'cls' in self.consistency_type:
                    return dino_head(feat_out), logits_out, dino_head(prompt_out[-1].reshape(B*PN, D)).reshape(B, PN, self.dino_out_dim)
                else:
                    return None, logits_out, dino_head(prompt_out[-1].reshape(B*PN, D)).reshape(B, PN, self.dino_out_dim)

            else:
                stages = len(prompt_out)
                prompt_out_list = []
                for i in range(stages):
                    B, PN, D = prompt_out[i].shape
                    prompt_out_list.append(dino_head[i](prompt_out[i].reshape(B*PN, D)).reshape(B, PN, self.dino_out_dim))
    
                if 'cls' in self.consistency_type:
                    return dino_head[-1](feat_out), logits_out, prompt_out_list
                else:
                    return None, logits_out, prompt_out_list

    def forward(self, im_q, st_type='student', cls_only=False):
        """
        Input:
            im_q: a batch of query images
            im_k: a batch of key images
        Output:
            feats_q: <B, D> query image features before normalization
            logits_q: <B, C> logits for class prediction from queries
            logits_ins: <B, K> logits for instance prediction
            k: <B, D> contrastive keys
        """

        if cls_only:
            # compute query features
            if st_type == 'student':
                feats_q, logits_q, _ = self.student(im_q, return_feats=True)
            else:
                feats_q, logits_q, _ = self.teacher(im_q, return_feats=True)
            return feats_q, logits_q
        
        else:
            # compute key features
            self._momentum_update_teacher()  # update the key encoder
            
            with torch.no_grad():
                teacher_output_cls, _, teacher_output_prompt = self.multi_crop_forward(im_q[0], mode='teacher')
            student_output_cls, student_logits, student_output_prompt = self.multi_crop_forward(im_q[1], mode='student')
            return teacher_output_cls, student_output_cls, student_logits, teacher_output_prompt, student_output_prompt


